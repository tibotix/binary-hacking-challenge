diff --git a/arch/x86_64/syscall_arch.h b/arch/x86_64/syscall_arch.h
index 4afa63a..cc5870a 100644
--- a/arch/x86_64/syscall_arch.h
+++ b/arch/x86_64/syscall_arch.h
@@ -1,25 +1,41 @@
 #define __SYSCALL_LL_E(x) (x)
 #define __SYSCALL_LL_O(x) (x)

+#define SYSCALL_INSNS "int $128"
+
 static __inline long __syscall0(long n)
 {
 	unsigned long ret;
-	__asm__ __volatile__ ("syscall" : "=a"(ret) : "a"(n) : "rcx", "r11", "memory");
+    __asm__ __volatile__(
+		"mov %%rdi, %%rax\n"
+        SYSCALL_INSNS
+        : "=a"(ret) :
+    );
 	return ret;
 }

 static __inline long __syscall1(long n, long a1)
 {
 	unsigned long ret;
-	__asm__ __volatile__ ("syscall" : "=a"(ret) : "a"(n), "D"(a1) : "rcx", "r11", "memory");
+    __asm__ __volatile__(
+		"mov %%rdi, %%rax\n"
+		"mov %%rsi, %%rdi\n"
+        SYSCALL_INSNS
+        : "=a"(ret) :
+    );
 	return ret;
 }

 static __inline long __syscall2(long n, long a1, long a2)
 {
 	unsigned long ret;
-	__asm__ __volatile__ ("syscall" : "=a"(ret) : "a"(n), "D"(a1), "S"(a2)
-						  : "rcx", "r11", "memory");
+    __asm__ __volatile__(
+		"mov %%rdi, %%rax\n"
+		"mov %%rsi, %%rdi\n"
+		"mov %%rdx, %%rsi\n"
+        SYSCALL_INSNS
+        : "=a"(ret) :
+    );
 	return ret;
 }

@@ -27,49 +43,74 @@ static __inline long __syscall2(long n, long a1, long a2)
 static __inline long __syscall3(long n, long a1, long a2, long a3)
 {
 	unsigned long ret;
-	__asm__ __volatile__ ("syscall" : "=a"(ret) : "a"(n), "D"(a1), "S"(a2),
-						  "d"(a3) : "rcx", "r11", "memory");
+    __asm__ __volatile__(
+		"mov %%rdi, %%rax\n"
+		"mov %%rsi, %%rdi\n"
+		"mov %%rdx, %%rsi\n"
+		"mov %%rcx, %%rdx\n"
+        SYSCALL_INSNS
+        : "=a"(ret) :
+    );
 	return ret;
 }

-/*
 static __inline long __syscall4(long n, long a1, long a2, long a3, long a4)
 {
 	unsigned long ret;
-	register long r10 __asm__("r10") = a4;
-	__asm__ __volatile__ ("syscall" : "=a"(ret) : "a"(n), "D"(a1), "S"(a2),
-						  "d"(a3), "r"(r10): "rcx", "r11", "memory");
+    __asm__ __volatile__(
+		"mov %%rdi, %%rax\n"
+		"mov %%rsi, %%rdi\n"
+		"mov %%rdx, %%rsi\n"
+		"mov %%rcx, %%rdx\n"
+		"mov %%r8, %%rcx\n"
+        SYSCALL_INSNS
+        : "=a"(ret) :
+    );
 	return ret;
 }

 static __inline long __syscall5(long n, long a1, long a2, long a3, long a4, long a5)
 {
 	unsigned long ret;
-	register long r10 __asm__("r10") = a4;
-	register long r8 __asm__("r8") = a5;
-	__asm__ __volatile__ ("syscall" : "=a"(ret) : "a"(n), "D"(a1), "S"(a2),
-						  "d"(a3), "r"(r10), "r"(r8) : "rcx", "r11", "memory");
+    __asm__ __volatile__(
+		"mov %%rdi, %%rax\n"
+		"mov %%rsi, %%rdi\n"
+		"mov %%rdx, %%rsi\n"
+		"mov %%rcx, %%rdx\n"
+		"mov %%r8, %%rcx\n"
+		"mov %%r9, %%r8\n"
+        SYSCALL_INSNS
+        : "=a"(ret) :
+    );
 	return ret;
 }

 static __inline long __syscall6(long n, long a1, long a2, long a3, long a4, long a5, long a6)
 {
-	unsigned long ret;
-	register long r10 __asm__("r10") = a4;
-	register long r8 __asm__("r8") = a5;
-	register long r9 __asm__("r9") = a6;
-	__asm__ __volatile__ ("syscall" : "=a"(ret) : "a"(n), "D"(a1), "S"(a2),
-						  "d"(a3), "r"(r10), "r"(r8), "r"(r9) : "rcx", "r11", "memory");
-	return ret;
+    unsigned long ret;
+	__asm__ __volatile__("mov %0, %%r10" : : "r"(a5) : "r10");
+    __asm__ __volatile__(
+		"mov %%rdi, %%rax\n"
+		"mov %%rsi, %%rdi\n"
+		"mov %%rdx, %%rsi\n"
+		"mov %%rcx, %%rdx\n"
+		"mov %%r8, %%rcx\n"
+		"mov %%r9, %%r8\n"
+		"mov %%r10, %%r9\n"
+        SYSCALL_INSNS
+        : "=a"(ret) :
+    );
+    return ret;
 }
-*/

+/*
 long int __syscall4(long int n,long int a1,long int a2,long int a3,
 		    long int a4);
 long int __syscall5(long int n,long int a1,long int a2,long int a3,
 		    long int a4,long int a5);
 long int __syscall6(long int n,long int a1,long int a2,long int a3,
 		    long int a4,long int a5,long int a6);
+*/

 #define VDSO_USEFUL
 #define VDSO_CGT_SYM "__vdso_clock_gettime"
